---
title: "Replication: The Structure of Inequality and the Politics of Redistribution"
author: "Filippo Teoldi, Zara Riaz and Julian Gerez"
date: "October 23rd, 2018"
output: pdf_document
---

```{r include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```

First we open the dataset with the `haven` package, which allows us to open .dta files.

```{r}
library('haven')
directory <- "~/Documents/GitHub/Lupu---Pontusson/"
data <- read_dta(paste0(directory, "LupPon_APSR.dta"))
```

## Data cleaning

First, the authors redefine inverse disproportionality measures, `disp_gall` as such.

```{r}
data$disp_gall <- data$disp_gall*-1
```

Then the variables female participation, `fempar`, and annual net union density, `union` are multiplied by 100 so that they are rescaled.

```{r}
data$fempar <- data$fempar*100
data$union <- data$union*100
```

The variables `pjoint` and `disp_gall`, are partisanship and disproportionality, respectively. These are standardized from [0,1]. To do so, we are defining a function, `range01`, which standardizes the range of a variable such that it takes on values from 0 to 1.

```{r}
range01 <- function(x, ...) {(x - min(x, ...)) / (max(x, ...) - min(x, ...))}

data$stdpjoint <- range01(data$pjoint, na.rm = TRUE)
data$stdpdisp_gall <- range01(data$disp_gall, na.rm = TRUE)
```

Next, we interpolate missing values by first defining all the variables that need to be interpolated: `pratio9050`, `pratio5010`, `pratio9050s`, `pratio5010s`, `pforeign`, and `pvoc`. To interpolate missing values for each country, rather than for the dataset as a whole, we write a loop to define the object `data_countries` as a list of the data (with these aforementioned new variables) subsetted by each country.

At this point, we can interpolate missing values for each variable. The `zoo` package allows use to use the function `na.approx` to linearly interpolate missing values. We use a set of loops that interpolates missing values indexed for each country, `i`, in our list of `data.frames`, `data_countries`, *for each variable*.[^1] Finally, we can use `rbind` to bind this new list into a single `data.frame`, and remove our list of `data.frames`.

[^1]: This is what `data_countries[[i]][,y>23]` refers to, where `i` is each country and `y` represents the new variables. The 24th column is `pratio9050`, the 25th column `pratio5010`, and so on. Each of these are interpolated using the original variables, which are represented in `data_countries[[i]][,z>5]`, where `z` represents the original variables corresponding the new variables (i.e. `pratio9050` is interpolated using `ratio9050`, which is in the 5th column, and so on). Note that the index along which the function is operating is by year (`data_contries[[i]][,3]`) for *every* variable. In other words, we are replacing the variables of interest in each country for missing years.

```{r}
library('zoo')

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
data_countries[[i]] <- cbind(data_countries[[i]], sapply(c(5:8, 16, 19), function(y)
   na.approx(data_countries[[i]][,y], x = index(data_countries[[i]][,3], data_countries[[i]][,y]), na.rm = FALSE)
  ))
}

data <- do.call("rbind", data_countries)

names(data)[24:29] <- c("pratio9050", "pratio5010", "pratio9050s", "pratio5010s", "pforeign", "pvoc")

rm(data_countries)
```

We generate an immigration measure, `fpop` which reflects the percentage of the population that is foreign-born by using our interpolated measure `pforeign`, multiplying it by 1000, and dividing this result by `pop`, which is total population.

```{r}
data$pforeign <- data$pforeign*1000
data$fpop <- (data$pforeign/data$pop)*100
```

Our last data cleaning step before moving on to generating the averages for the redistribution models is to generate additional measures of inequality as defined by manipulations to our existing measures of inequality: `ratio9010`, `ratio9010s`, `skew`, and `skews`.

```{r}
data$ratio9010 <- data$pratio9050*data$pratio5010
data$ratio9010s <- data$pratio9050s*data$pratio5010s #not extrapolated
data$skew <- data$pratio9050/data$pratio5010
data$skews <- data$pratio9050s/data$pratio5010s #not extrapolated
```

Because data on redistribution are unequally spaced for the period of the study, the authors use a time series cross sectional model where the indepdent variables are averaged across the period since the last redistribution observation. 

We generate moving averages for the redistribution models by using a series of loops. First we generate the `since` variable, which represents the years since the last redistribution, `redist`, for each country. We remake our list of the subset of countries as before and define `since` (`data_countries[[i]][35]`) accordingly by creating a new logical vector, `nona`, that tells us when the `redist` variable is and is not defined for each country.

```{r}
data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  data_countries[[i]] <- cbind(data_countries[[i]], NA)
  nona <- !is.na(data_countries[[i]][,4])
  data_countries[[i]][,35][nona] <- c(NA, diff(data_countries[[i]][,3][nona]))
}

data <- do.call("rbind", data_countries)
names(data)[35] <- "since"
rm(data_countries)
```

Now we can calculate the moving averages:

```{r}
library('dplyr')

# Calculate moving average for ratio9010 (var31)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+j] <- lag(rollapply(data_countries[[i]][,31], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in 37:ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvratio9010 <- NA

data[,46] <- case_when(
  data[,35] %in% 1 ~ data[,36],
  data[,35] %in% 2 ~ data[,37],
  data[,35] %in% 3 ~ data[,38],
  data[,35] %in% 4 ~ data[,39],
  data[,35] %in% 5 ~ data[,40],
  data[,35] %in% 6 ~ data[,41],
  data[,35] %in% 7 ~ data[,42],
  data[,35] %in% 8 ~ data[,43],
  data[,35] %in% 9 ~ data[,44],
  data[,35] %in% 10 ~ data[,45]
)

data[,46][is.na(data[,35]) & !is.na(data[,4])] <- data[,45][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:35,46)]

# Calculate moving average for pratio9050 (var24)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+1+j] <- lag(rollapply(data_countries[[i]][,24], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+1):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvpratio9050 <- NA

data[,46+1] <- case_when(
  data[,35] %in% 1 ~ data[,36+1],
  data[,35] %in% 2 ~ data[,37+1],
  data[,35] %in% 3 ~ data[,38+1],
  data[,35] %in% 4 ~ data[,39+1],
  data[,35] %in% 5 ~ data[,40+1],
  data[,35] %in% 6 ~ data[,41+1],
  data[,35] %in% 7 ~ data[,42+1],
  data[,35] %in% 8 ~ data[,43+1],
  data[,35] %in% 9 ~ data[,44+1],
  data[,35] %in% 10 ~ data[,45+1]
)

data[,46+1][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+1][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+1),46+1)]

# Calculate moving average for pratio5010 (var25)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+2+j] <- lag(rollapply(data_countries[[i]][,25], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+2):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvpratio5010 <- NA

data[,46+2] <- case_when(
  data[,35] %in% 1 ~ data[,36+2],
  data[,35] %in% 2 ~ data[,37+2],
  data[,35] %in% 3 ~ data[,38+2],
  data[,35] %in% 4 ~ data[,39+2],
  data[,35] %in% 5 ~ data[,40+2],
  data[,35] %in% 6 ~ data[,41+2],
  data[,35] %in% 7 ~ data[,42+2],
  data[,35] %in% 8 ~ data[,43+2],
  data[,35] %in% 9 ~ data[,44+2],
  data[,35] %in% 10 ~ data[,45+2]
)

data[,46+2][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+2][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+2),46+2)]

# Calculate moving average for stdpjoint (var22)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+3+j] <- lag(rollapply(data_countries[[i]][,22], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+3):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvstdpjoint <- NA

data[,46+3] <- case_when(
  data[,35] %in% 1 ~ data[,36+3],
  data[,35] %in% 2 ~ data[,37+3],
  data[,35] %in% 3 ~ data[,38+3],
  data[,35] %in% 4 ~ data[,39+3],
  data[,35] %in% 5 ~ data[,40+3],
  data[,35] %in% 6 ~ data[,41+3],
  data[,35] %in% 7 ~ data[,42+3],
  data[,35] %in% 8 ~ data[,43+3],
  data[,35] %in% 9 ~ data[,44+3],
  data[,35] %in% 10 ~ data[,45+3]
)

data[,46+3][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+3][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+3),46+3)]

# Calculate moving average for skew (var33)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+4+j] <- lag(rollapply(data_countries[[i]][,33], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+4):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvskew <- NA

data[,46+4] <- case_when(
  data[,35] %in% 1 ~ data[,36+4],
  data[,35] %in% 2 ~ data[,37+4],
  data[,35] %in% 3 ~ data[,38+4],
  data[,35] %in% 4 ~ data[,39+4],
  data[,35] %in% 5 ~ data[,40+4],
  data[,35] %in% 6 ~ data[,41+4],
  data[,35] %in% 7 ~ data[,42+4],
  data[,35] %in% 8 ~ data[,43+4],
  data[,35] %in% 9 ~ data[,44+4],
  data[,35] %in% 10 ~ data[,45+4]
)

data[,46+4][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+4][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+4),46+4)]

# Calculate moving average for stddisp_gall (var23) 

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+5+j] <- lag(rollapply(data_countries[[i]][,23], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+5):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvstddisp_gall <- NA

data[,46+5] <- case_when(
  data[,35] %in% 1 ~ data[,36+5],
  data[,35] %in% 2 ~ data[,37+5],
  data[,35] %in% 3 ~ data[,38+5],
  data[,35] %in% 4 ~ data[,39+5],
  data[,35] %in% 5 ~ data[,40+5],
  data[,35] %in% 6 ~ data[,41+5],
  data[,35] %in% 7 ~ data[,42+5],
  data[,35] %in% 8 ~ data[,43+5],
  data[,35] %in% 9 ~ data[,44+5],
  data[,35] %in% 10 ~ data[,45+5]
)

data[,46+5][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+5][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+5),46+5)]

# Calculate moving average for pvoc (var29)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+6+j] <- lag(rollapply(data_countries[[i]][,29], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+6):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvpvoc <- NA

data[,46+6] <- case_when(
  data[,35] %in% 1 ~ data[,36+6],
  data[,35] %in% 2 ~ data[,37+6],
  data[,35] %in% 3 ~ data[,38+6],
  data[,35] %in% 4 ~ data[,39+6],
  data[,35] %in% 5 ~ data[,40+6],
  data[,35] %in% 6 ~ data[,41+6],
  data[,35] %in% 7 ~ data[,42+6],
  data[,35] %in% 8 ~ data[,43+6],
  data[,35] %in% 9 ~ data[,44+6],
  data[,35] %in% 10 ~ data[,45+6]
)

data[,46+6][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+6][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+6),46+6)]

# Calculate moving average for union (var12)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+7+j] <- lag(rollapply(data_countries[[i]][,12], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+7):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvunion <- NA

data[,46+7] <- case_when(
  data[,35] %in% 1 ~ data[,36+7],
  data[,35] %in% 2 ~ data[,37+7],
  data[,35] %in% 3 ~ data[,38+7],
  data[,35] %in% 4 ~ data[,39+7],
  data[,35] %in% 5 ~ data[,40+7],
  data[,35] %in% 6 ~ data[,41+7],
  data[,35] %in% 7 ~ data[,42+7],
  data[,35] %in% 8 ~ data[,43+7],
  data[,35] %in% 9 ~ data[,44+7],
  data[,35] %in% 10 ~ data[,45+7]
)

data[,46+7][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+7][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+7),46+7)]

# Calculate moving average for fpop (var30)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+8+j] <- lag(rollapply(data_countries[[i]][,30], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+8):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvfpop <- NA

data[,46+8] <- case_when(
  data[,35] %in% 1 ~ data[,36+8],
  data[,35] %in% 2 ~ data[,37+8],
  data[,35] %in% 3 ~ data[,38+8],
  data[,35] %in% 4 ~ data[,39+8],
  data[,35] %in% 5 ~ data[,40+8],
  data[,35] %in% 6 ~ data[,41+8],
  data[,35] %in% 7 ~ data[,42+8],
  data[,35] %in% 8 ~ data[,43+8],
  data[,35] %in% 9 ~ data[,44+8],
  data[,35] %in% 10 ~ data[,45+8]
)

data[,46+8][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+8][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+8),46+8)]

# Calculate moving average for fempar (var10)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+9+j] <- lag(rollapply(data_countries[[i]][,10], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+9):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvfempar <- NA

data[,46+9] <- case_when(
  data[,35] %in% 1 ~ data[,36+9],
  data[,35] %in% 2 ~ data[,37+9],
  data[,35] %in% 3 ~ data[,38+9],
  data[,35] %in% 4 ~ data[,39+9],
  data[,35] %in% 5 ~ data[,40+9],
  data[,35] %in% 6 ~ data[,41+9],
  data[,35] %in% 7 ~ data[,42+9],
  data[,35] %in% 8 ~ data[,43+9],
  data[,35] %in% 9 ~ data[,44+9],
  data[,35] %in% 10 ~ data[,45+9]
)

data[,46+9][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+9][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+9),46+9)]

# Calculate moving average for unempl (var11)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+10+j] <- lag(rollapply(data_countries[[i]][,11], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+10):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvunempl <- NA

data[,46+10] <- case_when(
  data[,35] %in% 1 ~ data[,36+10],
  data[,35] %in% 2 ~ data[,37+10],
  data[,35] %in% 3 ~ data[,38+10],
  data[,35] %in% 4 ~ data[,39+10],
  data[,35] %in% 5 ~ data[,40+10],
  data[,35] %in% 6 ~ data[,41+10],
  data[,35] %in% 7 ~ data[,42+10],
  data[,35] %in% 8 ~ data[,43+10],
  data[,35] %in% 9 ~ data[,44+10],
  data[,35] %in% 10 ~ data[,45+10]
)

data[,46+10][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+10][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+10),46+10)]

# Calculate moving average for turnout (var13)

data_countries <- lapply(unique(data$country), function(x)
  subset(data, data$country==x)
)

for (i in 1:length(data_countries)){
  for (j in 1:10) {
    data_countries[[i]][,35+11+j] <- lag(rollapply(data_countries[[i]][,13], j, FUN = mean, fill = NA, align = "right"),1)
  }
}

data <- do.call("rbind", data_countries)

for(x in c(37+11):ncol(data)){
    # Nested loop starts from first row
    for(y in 2:nrow(data)){
        # Check for NA
        if(is.na(data[y,x])){
            data[y,x] <- data[y,x-1]
        }
    }
}

data$dvturnout <- NA

data[,46+11] <- case_when(
  data[,35] %in% 1 ~ data[,36+11],
  data[,35] %in% 2 ~ data[,37+11],
  data[,35] %in% 3 ~ data[,38+11],
  data[,35] %in% 4 ~ data[,39+11],
  data[,35] %in% 5 ~ data[,40+11],
  data[,35] %in% 6 ~ data[,41+11],
  data[,35] %in% 7 ~ data[,42+11],
  data[,35] %in% 8 ~ data[,43+11],
  data[,35] %in% 9 ~ data[,44+11],
  data[,35] %in% 10 ~ data[,45+11]
)

data[,46+11][is.na(data[,35]) & !is.na(data[,4])] <- data[,45+11][is.na(data[,35]) & !is.na(data[,4])]

data <- data[,c(0:(35+11),46+11)]

rm(data_countries)
```

Now, we match these moving averages to redistribution observations by creating a new set of independent variables with values that correspond to the correct moving average based on the period of redistribution. There are three possible scenarios here:
1) A redistribution observation is observed 1 year after the previous: the independent variable takes on its 1-year lagged value.
2) A redistribution observation is observed n years ago, where n is [2,10]: the independent variable takes on its nth year moving average value.
3) A redstribution observation is the first observation for the country: the indpeendnet variable takes on its 10th year moving average value. 

Social Spending: To estimate the model using the 2nd dependent variable (socspend), we create five-year moving averages for this variable and all independent variables in the vector `c(20, 26:27, 32, 34, 21, 15, 22:23, 10:13, 29:30)`, that is `c("ma_socspend", "ma_pratio9050s", "ma_pratio5010s", "ma_pratio9010s", "ma_skews", "ma_dreher", "ma_pop65", "ma_stdpjoint", "ma_stddisp_gall", "ma_fempar", "ma_unempl", "ma_union", "ma_turnout", "ma_pvoc", "ma_fpop"`  to represent a slow-moving causal process.

```{r}
data <- cbind(data, sapply(c(20, 26:27, 32, 34, 21, 15, 22:23, 10:13, 29:30), function(x)
  (lag(data[,x], 1)+lag(data[,x], 2)+lag(data[,x], 3)+lag(data[,x], 4)+lag(data[,x], 5))/5
))

names(data)[48:62] <- c("ma_socspend", "ma_pratio9050s", "ma_pratio5010s", "ma_pratio9010s", "ma_skews", "ma_dreher", "ma_pop65", "ma_stdpjoint", "ma_stddisp_gall", "ma_fempar", "ma_unempl", "ma_union", "ma_turnout", "ma_pvoc", "ma_fpop")
```

# Design declaration

We start by loading in the `DeclareDesign` package and defining the elements of the design.

* `declare_population` refers to the sample size of the study. The study concerns country-year units. In this case, there are 858 observations.
* `declare_potential_oucomes` refers to

```{r}
library('DeclareDesign')

# X: take some parameters based on a simple model of X on Y

modX <- lm(data$redist ~ data$skew)
a_X <- summary(modX)$coefficients["(Intercept)","Estimate"]
b_X <- summary(modX)$coefficients["data$skew","Estimate"]
sd_X <- 1

rho_XY <- -.5 # Confounding 
sd_X_type <- .1 # sd on effect heterogeneity
sd_Y_type <- .005 # sd on compliance heterogeneity
rho_XY_type <- 0 # Possible correlation between compliance and effects
```

```{r}
population <- declare_population(
  N = 858,
  redist = sample(data$redist, N, replace = TRUE),
  u_X = rnorm(N, sd = sd_X),
  u_X_type = rnorm(N, df = sd_X_type)
)
```

```{r}
fx <- function(a_X, b_X, u_X_type, u_X)
a_X + (b_X + u_X_type) + u_X

potentials <- declare_step(handler = fabricate, 
  redist = fx(skew, a_X, b_X, u_X_type, u_X))
```

```{r}
estimand <- declare_estimand(
  ols = mean((fx(max(skew), a_X, b_X, u_X_type, u_X) - fx(min(skew), a_X, b_X, u_X_type, u_X))/(max(skew) - min(skew))))
```

```{r}
estimator_1 <- declare_estimator(redist ~ skew, estimand = "ols", 
model = lm_robust, label = "lm")
```

```{r}
lupu_pontusson_2011_design <- population + potentials + estimand + estimator_1
```
# Replication

```{r}
# remove variables we don't need
data_redist <- data[,c(1:4, 37:38, 36, 40, 47, 45, 41:42, 43, 46 )]

# Subsetting data
redistsample <- data[!is.na(data$redist),]

# Sorting data
redistsample <- redistsample[with(redistsample, order(id, year)),]

# create lag
redistsample$redist_lag <- unlist(by(redistsample,redistsample$id,function(x){c(NA,x[,"redist"][1:(length(x[,"redist"])-1)])}))

# set time series
redistsample$time<- unlist(by(redistsample,redistsample$id,function(x) seq(1:nrow(x))))
```

# Specification 1: 

```{r}
library('panelAR')
out1 <- panelAR(redist ~ redist_lag + dvpratio9050 + dvpratio5010 + dvturnout + dvfempar + dvstddisp_gall + dvpvoc + dvunion + dvunempl, data=redistsample, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out1)
```

---

# Specification 2 (remove outliers)

```{r}
#defining outliers 
mod1.resid <- out1$residuals
index <- which(abs((mod1.resid-mean(mod1.resid))/sd(mod1.resid)) <= 1.5)
#creating a new subset without these observations
redistsample_noout<- out1$model[index,]

#running same model as spec1 with new subset
out2 <- panelAR(redist ~ redist_lag + dvpratio9050 + dvpratio5010 + dvturnout + dvfempar + dvstddisp_gall + dvpvoc + dvunion + dvunempl, data=redistsample_noout, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out2)
```

# Specification 3 (no controls)
```{r}
out3 <- panelAR(redist ~ dvpratio9050 + dvpratio5010 + as.factor(id), data=redistsample, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out3)
```

# Specification 4 (no controls, no outliers)

```{r}
#defining outliers 
mod3.resid <- out3$residuals
index <- which(abs((mod3.resid-mean(mod3.resid))/sd(mod3.resid)) <= 1.5)
#creating a new subset without these observations
redistsample_noout<- out3$model[index,]
#running same model as spec3 with new subset
out4 <- panelAR(redist ~ dvpratio9050 + dvpratio5010 + as.factor(id), data=redistsample_noout, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out4)
```

# Specification 5 (Using skew as main inequality measure)

```{r}
out5<- panelAR(redist ~ redist_lag + dvratio9010 + dvskew + dvturnout + dvfempar + dvstddisp_gall + dvpvoc + dvunion + dvunempl, data=redistsample, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
summary(out5)
```

# Specification 6 (Skew as main measure, no outliers)

```{r}
mod5.resid <- out5$residuals
index <- which(abs((mod5.resid-mean(mod5.resid))/sd(mod5.resid)) <= 1.5)
#creating a new subset without these observations
redistsample_noout<- out5$model[index,]
#running same model as spec5 with new subset
out6<- panelAR(redist ~ redist_lag + dvratio9010 + dvskew + dvturnout + dvfempar + dvstddisp_gall + dvpvoc + dvunion + dvunempl, data=redistsample_noout, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
summary(out6)
```

# Specification 7 (Skew as main measure, no controls, country fixed effects)

```{r}
out7 <- panelAR(redist ~ dvratio9010 + dvskew + as.factor(id), data=redistsample, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out7)
```

# Specification 8 (Skew as main measure, no controls, fixed effects without outliers)

```{r}
mod7.resid <- out7$residuals
index <- which(abs((mod7.resid-mean(mod7.resid))/sd(mod7.resid)) <= 1.5)
#creating a new subset without these observations
redistsample_noout<- out7$model[index,]
#running same model as spec7 with new subset
out8 <- panelAR(redist ~ dvratio9010 + dvskew + as.factor(id), data=redistsample_noout, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out8)
```

For the next table, we use the same 8 specifications but replace our dependent variable with social spending (socspend) and the 5-year moving averages of the independent variable names. 
We use the full data set for these specifications, except when we drop the outliers. The independent variables included are:
socspend.lag mapratio9050s mapratio5010s mapop65 mafempar maturnout mastddisp_gall mapvoc maunion maunempl madreher gdpgrowth, where the "ma" prefixes denotes moving average.

```{r}

# remove variables we don't need
data_socspend <- data[,c(1:3, 18, 20, 48:62 )]

# Sorting data
data_socspend  <- data_socspend [with(data_socspend , order(id, year)),]

# create lag
data_socspend $socspend_lag <- unlist(by(data_socspend ,data_socspend $id,function(x){c(NA,x[,"socspend"][1:(length(x[,"socspend"])-1)])}))

# set time series
data_socspend $time<- unlist(by(data_socspend ,data_socspend $id,function(x) seq(1:nrow(x))))
```
Specification 9: 
```{r}
out9 <- panelAR(socspend ~ socspend_lag + ma_pratio9050s + ma_pratio5010s + ma_pop65+ ma_turnout + ma_fempar + ma_stddisp_gall + ma_pvoc + ma_union + ma_unempl + ma_dreher + gdpgrowth, data=data_socspend , panelVar='id', timeVar='time', autoCorr='psar1', panelCorrMethod='pcse',rho.na.rm=TRUE, bound.rho=TRUE)
summary(out9)

```

# Specification 10 (remove outliers)

```{r}
#defining outliers 
mod9.resid <- out9$residuals
index <- which(abs((mod9.resid-mean(mod9.resid))/sd(mod9.resid)) <= 1.5)
#creating a new subset without these observations
data_noout<- out9$model[index,]

#running same model as spec9 with new subset
out10 <- panelAR(socspend ~ socspend_lag + ma_pratio9050s + ma_pratio5010s + ma_pop65+ ma_turnout + ma_fempar + ma_stddisp_gall + ma_pvoc + ma_union + ma_unempl + ma_dreher + gdpgrowth, data=data_noout, panelVar='id', timeVar='time', autoCorr='psar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out10)
```

# Specification 11 (no controls)
```{r}
out11 <- panelAR(socspend ~ ma_pratio9050s + ma_pratio5010s +gdpgrowth + as.factor(id), data=data_socspend , panelVar='id', timeVar='time', autoCorr='psar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out11)
```

# Specification 12 (no controls, no outliers)
```{r}
#defining outliers 
mod11.resid <- out11$residuals
index <- which(abs((mod11.resid-mean(mod11.resid))/sd(mod11.resid)) <= 1.5)
#creating a new subset without these observations
data_noout<- out11$model[index,]
#running same model as spec11 with new subset
out12 <- panelAR(socspend ~ ma_pratio9050s + ma_pratio5010s +gdpgrowth+ as.factor(id), data=data_noout, panelVar='id', timeVar='time', autoCorr='psar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out12)
```

#Specification 13 (Using skew as main inequality measure)
```{r}
out13<- panelAR(socspend ~ socspend_lag + ma_pratio9010s + ma_skews + ma_pop65+ ma_turnout + ma_fempar + ma_stddisp_gall + ma_pvoc + ma_union + ma_unempl + ma_dreher + gdpgrowth, data=data_socspend, panelVar='id', timeVar='time', autoCorr='psar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
summary(out13)
```

#Specification 14 (Skew as main measure, no outliers)
```{r}
mod13.resid <- out13$residuals
index <- which(abs((mod13.resid-mean(mod13.resid))/sd(mod13.resid)) <= 1.5)
#creating a new subset without these observations
data_noout<- out13$model[index,]
#running same model as spec13 with new subset
out14<- panelAR(socspend ~ socspend_lag + ma_pratio9010s + ma_skews + ma_pop65+ ma_turnout + ma_fempar + ma_stddisp_gall + ma_pvoc + ma_union + ma_unempl + ma_dreher + gdpgrowth, data=data_noout, panelVar='id', timeVar='time', autoCorr='psar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
summary(out14)
```

#Specification 15 (Skew as main measure, no controls, country fixed effects)
```{r}
out15 <- panelAR(socspend ~ ma_pratio9010s + ma_skews +gdpgrowth+ as.factor(id), data=data_socspend, panelVar='id', timeVar='time', autoCorr='psar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out15)	
```

# Specification 16 (Skew as main measure, no controls, fixed effects without outliers)
```{r}
mod15.resid <- out15$residuals
index <- which(abs((mod15.resid-mean(mod15.resid))/sd(mod15.resid)) <= 1.5)
#creating a new subset without these observations
data_noout<- out15$model[index,]
#running same model as spec15 with new subset
out16 <- panelAR(socspend ~ ma_pratio9010s + ma_skews +gdpgrowth + as.factor(id), data=data_noout, panelVar='id', timeVar='time', autoCorr='psar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out16)
```

##Immigration Models (Table 4)

#Specification 17 (Redistribution as main DV, adding dvfpop)
```{r}
out17 <- panelAR(redist ~ redist_lag + dvskew + dvratio9010 + dvturnout + dvfempar + dvstddisp_gall + dvpvoc + dvunion + dvunempl +dvfpop, data=redistsample, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out17)
```

# Specification 18 (remove outliers)

```{r}
#defining outliers 
mod17.resid <- out17$residuals
index <- which(abs((mod17.resid-mean(mod17.resid))/sd(mod17.resid)) <= 1.5)
#creating a new subset without these observations
redistsample_noout<- out17$model[index,]

#running same model as spec17 with new subset
out18 <- panelAR(redist ~ redist_lag + dvskew + dvratio9010+  dvturnout + dvfempar + dvstddisp_gall + dvpvoc + dvunion + dvunempl +dvfpop, data=redistsample_noout, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
summary(out18)
```

# Specification 19 (Social spending as main DV, adding dvfpop)

```{r}
out19<- panelAR(socspend ~ socspend_lag + ma_pratio9010s + ma_skews + ma_pop65+ ma_turnout + ma_fempar + ma_stddisp_gall + ma_pvoc + ma_union + ma_unempl + ma_dreher +ma_fpop + gdpgrowth, data=data_socspend, panelVar='id', timeVar='time', autoCorr='psar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
print(summary(out19))
```

#Specification 20 (removing outliers)
```{r}
#defining outliers 
mod19.resid <- out19$residuals
index <- which(abs((mod19.resid-mean(mod19.resid))/sd(mod19.resid)) <= 1.5)
#creating a new subset without these observations
data_noout<- out19$model[index,]

#running same model as spec19 with new subset
out20<- panelAR(socspend ~ socspend_lag + ma_pratio9010s + ma_skews + ma_pop65+ ma_turnout + ma_fempar + ma_stddisp_gall + ma_pvoc + ma_union + ma_unempl + ma_dreher +ma_fpop + gdpgrowth, data=data_noout, panelVar='id', timeVar='time', autoCorr='psar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
print(summary(out20))
```

## Partisanship (Table 5)

```{r}
#Creating a new data subset that excludes 1979 and earlier years

recentyears <- subset(data, year>1979)

recentyears <- recentyears[with(recentyears , order(id, year)),]

#test <- test[order(test$id, test$year),]

# set time series
recentyears$time<- unlist(by(recentyears ,recentyears$id,function(x) seq(1:nrow(x))))

```

#Specification 21 (IVs include skew, proportionality, and turnout)

```{r}
out21<- panelAR(stdpjoint ~ ma_skews + ma_stddisp_gall + ma_turnout , data=recentyears, panelVar='id', timeVar='time', autoCorr='none', panelCorrMethod='none',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
summary(out21)
```

#Specification 22 (Adding globalization)

```{r}
out22<- panelAR(stdpjoint~ma_skews + mastddisp_gall + maturnout +madreher , data=recentyears, panelVar='id', timeVar='time', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
print(summary(out22))
```

#Specification 23 (Adding immigration)

```{r}
out23<- panelAR(stdpjoint~maskews + mastddisp_gall + maturnout +madreher +mafpop , data=recentyears, panelVar='id', timeVar='time', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
print(summary(out23))
```

```{r}
#creating a new data frame with observations before 1980
olderyears<- subset(data, year<1980)

aggdata <-aggregate(stdpjoint, skew, stddisp_gall, dreher, fpop, turnout, by=list(id),mean)
```

#Specification 24 

```{r}
out24 <- panelAR(stdpjoint~maskews + mastddisp_gall + maturnout , data=olderyears, panelVar='id', timeVar='time', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
print(summary(out24))
```

#Specification 25 (Specification 22 without outliers)
```{r}
out25 <- panelAR(stdpjoint~maskews + mastddisp_gall + maturnout +madreher , data=olderyears, panelVar='id', timeVar='time', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
print(summary(out25))
```

#Specification 26 (Specification 23 without outliers)
```{r}
out26 <- panelAR(stdpjoint~maskews + mastddisp_gall + maturnout +madreher +mafpop , data=olderyears, panelVar='id', timeVar='time', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
print(summary(out26))
```

##Redistribution and Social Spending Models with partisanship measures (Table 6)

# Specification 27 (Redistribution as main DV, adding dvstdpjoint)
```{r}
out27 <- panelAR(redist ~ redist_lag + dvskew + dvratio9010 + dvturnout + dvfempar + dvstddisp_gall + dvpvoc + dvunion + dvunempl +dvfpop +dvstdpjoint, data=redistsample, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
print(summary(out27))
```

# Specification 28 (remove outliers)

```{r}
#defining outliers 
mod27.resid <- out27$residuals
index <- which(abs((mod27.resid-mean(mod27.resid))/sd(mod27.resid)) <= 1.5)
#creating a new subset without these observations
redistsample_noout<- out27$model[index,]

#running same model as spec17 with new subset
out28 <- panelAR(redist ~ redist.lag + dvskew + dvturnout + dvfempar + dvpropind + dvpvoc + dvunion + dvunempl +dvfpop +dvstdpjoint, data=redistsample_noout, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE)
print(summary(out28))
```

#Specification 29 (Social spending as main DV, adding dvstdpjoint)

```{r}
out29<- panelAR(socspend ~ socspend.lag + maratio9010s + maskews + mapop65+ maturnout + mafempar + mastdisp_gall + mapvoc + maunion + maunempl + madreher +dvfpop +dvstdpjoint + gdpgrowth, data=data, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
print(summary(out29))
```

#Specification 30 (removing outliers)

```{r}
#defining outliers 
mod29.resid <- out29$residuals
index <- which(abs((mod29.resid-mean(mod29.resid))/sd(mod29.resid)) <= 1.5)
#creating a new subset without these observations
redistsample_noout<- out29$model[index,]
#running same model as spec29 with new subset
out30<- panelAR(socspend ~ socspend.lag + maratio9010s + maskews + mapop65+ maturnout + mafempar + mastdisp_gall + mapvoc + maunion + maunempl + madreher +dvfpop  +dvstdpjoint +gdpgrowth, data=data_noout, panelVar='id', timeVar='time', autoCorr='ar1', panelCorrMethod='pcse',rho.na.rm=TRUE, panel.weight='t-1', bound.rho=TRUE) 
print(summary(out30))
```

# Extension
```{r}

#Loading data that contains disaggregated data for 6 categories of social spending
disag_data <- read_dta(paste0(directory, "disag_spending.dta"))

#Linearly interpolating missing values
library('zoo')

disagdata_countries <- lapply(unique(disag_data$country), function(x)
  subset(disag_data, disag_data$country==x)
)






test <- disagdata_countries[[1]]
test2 <- md.pattern(test)

test3 <- mice(test,m=5,maxit=50,meth='pmm',seed=500)
summary(mice(test,m=5,maxit=50,meth='pmm',seed=500))

completedData <- complete(test3, 1)

for (i in 1:length(disagdata_countries)){
disagdata_countries[[i]] <- cbind(disagdata_countries[[i]], sapply(c(5:8), function(y)
   na.approx(disagdata_countries[[i]][,y], x = index(disagdata_countries[[i]][,3], disagdata_countries[[i]][,y]), na.rm = FALSE)
  ))
}

disag_data <- do.call("rbind", disagdata_countries)


#names(disag_data)[9:12] <- c("fambenefits_v2", "incapacity_v2", "pubspending_labor_v2", "public_unemp_v2")

#rm(disagdata_countries)

```

